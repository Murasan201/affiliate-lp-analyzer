{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 LP Analyzer - アフィリエイトLP自動分析ツール\n",
    "\n",
    "このNotebookを使用することで、**プログラミング知識がなくても**簡単にランディングページ（LP）を分析できます！\n",
    "\n",
    "## 📋 このツールでできること\n",
    "\n",
    "- 🎭 **ペルソナ分析**: どんな人がターゲットなのかを分析\n",
    "- 💎 **USP抽出**: 商品・サービスの独自の強みを発見\n",
    "- 🎁 **ベネフィット分析**: お客様が得られる価値を整理\n",
    "- ✍️ **コピー手法分析**: 使われている心理テクニックを解析\n",
    "- 📝 **記事作成ガイド**: アフィリエイト記事のポイントを提案\n",
    "\n",
    "## 🚀 使い方（3ステップで完了！）\n",
    "\n",
    "1. **セットアップ**: 下のセルを実行してツールを準備\n",
    "2. **URL入力**: 分析したいLPのURLを入力\n",
    "3. **分析開始**: ボタンを押して結果を確認\n",
    "\n",
    "---\n",
    "\n",
    "**⚠️ 重要**: このツールを使用するには**OpenAI APIキー**が必要です。  \n",
    "まだお持ちでない場合は [OpenAI公式サイト](https://platform.openai.com/) でアカウントを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 ステップ1: 必要なツールをインストール\n",
    "\n",
    "**この作業は初回のみ必要です**  \n",
    "下のセルを実行すると、分析に必要なプログラムが自動的にインストールされます。\n",
    "\n",
    "⏱️ **所要時間**: 約2-3分（インターネット速度により変動）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 必要なライブラリをインストール\n",
    "print(\"🔧 ツールのセットアップを開始します...\")\n",
    "print(\"⏳ しばらくお待ちください（2-3分程度）\")\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 必要なパッケージのリスト\n",
    "packages = [\n",
    "    'playwright>=1.40.0',\n",
    "    'beautifulsoup4>=4.12.0', \n",
    "    'lxml>=4.9.0',\n",
    "    'openai>=1.0.0',\n",
    "    'pandas>=2.0.0',\n",
    "    'asyncio-throttle>=1.0.2',\n",
    "    'aiofiles>=23.0.0',\n",
    "    'python-dotenv>=1.0.0',\n",
    "    'markdownify>=0.11.0',\n",
    "    'tenacity>=8.2.0',\n",
    "    'ipywidgets>=8.0.0',\n",
    "    'tqdm>=4.65.0'\n",
    "]\n",
    "\n",
    "# パッケージを1つずつインストール\n",
    "for i, package in enumerate(packages, 1):\n",
    "    print(f\"📦 {i}/{len(packages)}: {package.split('>=')[0]} をインストール中...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        print(f\"   ✅ 完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ エラー: {e}\")\n",
    "\n",
    "print(\"\\n🌐 ブラウザエンジンをインストール中...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\", \"--with-deps\"])\n",
    "    print(\"✅ ブラウザエンジンのインストール完了\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ブラウザエンジンのインストールでエラー: {e}\")\n",
    "    print(\"💡 Google Colabをご利用の場合、このエラーは無視して次に進んでください\")\n",
    "\n",
    "print(\"\\n🎉 セットアップ完了！次のセルに進んでください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 ステップ2: 分析プログラムを読み込み\n",
    "\n",
    "**LP分析の核となるプログラムを準備します**  \n",
    "このセルでは、ランディングページを分析するためのAI機能を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 LP分析に必要な機能を読み込み\n",
    "print(\"🧠 AI分析エンジンを準備中...\")\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "# UI関連\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Web関連\n",
    "try:\n",
    "    from playwright.async_api import async_playwright\n",
    "    playwright_available = True\n",
    "except ImportError:\n",
    "    playwright_available = False\n",
    "    print(\"⚠️ Playwrightが利用できません。代替手段を使用します。\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# AI関連\n",
    "from openai import AsyncOpenAI\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "print(\"✅ ライブラリの読み込み完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 ウェブページ抽出機能を定義\n",
    "print(\"🔍 ウェブページ分析機能を準備中...\")\n",
    "\n",
    "@dataclass\n",
    "class ExtractedContent:\n",
    "    \"\"\"抽出されたLP内容を格納するクラス\"\"\"\n",
    "    url: str\n",
    "    title: str = \"\"\n",
    "    meta_description: str = \"\"\n",
    "    headings: Dict[str, List[str]] = None\n",
    "    main_text: str = \"\"\n",
    "    cta_elements: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.headings is None:\n",
    "            self.headings = {}\n",
    "        if self.cta_elements is None:\n",
    "            self.cta_elements = []\n",
    "\n",
    "async def extract_content_playwright(url: str) -> ExtractedContent:\n",
    "    \"\"\"Playwrightを使用してウェブページの内容を抽出\"\"\"\n",
    "    content = ExtractedContent(url=url)\n",
    "    \n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch(headless=True)\n",
    "            page = await browser.new_page()\n",
    "            \n",
    "            # ページにアクセス\n",
    "            await page.goto(url, timeout=30000, wait_until=\"networkidle\")\n",
    "            await page.wait_for_load_state(\"domcontentloaded\")\n",
    "            \n",
    "            # HTMLを取得\n",
    "            html = await page.content()\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            \n",
    "            await browser.close()\n",
    "            \n",
    "            # 内容を抽出\n",
    "            content.title = soup.find('title').get_text().strip() if soup.find('title') else \"\"\n",
    "            \n",
    "            meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "            content.meta_description = meta_desc.get('content', '').strip() if meta_desc else \"\"\n",
    "            \n",
    "            # 見出しを抽出\n",
    "            for level in range(1, 7):\n",
    "                tag_name = f'h{level}'\n",
    "                headings = soup.find_all(tag_name)\n",
    "                if headings:\n",
    "                    content.headings[tag_name] = [h.get_text().strip() for h in headings]\n",
    "            \n",
    "            # メインテキストを抽出\n",
    "            for tag in soup(['script', 'style', 'nav', 'header', 'footer']):\n",
    "                tag.decompose()\n",
    "            \n",
    "            main_element = soup.find('main') or soup.find('body') or soup\n",
    "            content.main_text = main_element.get_text(separator=' ', strip=True)[:8000]  # 8000文字制限\n",
    "            \n",
    "            # CTA要素を抽出\n",
    "            cta_buttons = soup.find_all(['button', 'a'], class_=re.compile(r'btn|button|cta', re.I))\n",
    "            content.cta_elements = [btn.get_text().strip() for btn in cta_buttons if btn.get_text().strip()]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Playwright抽出エラー: {e}\")\n",
    "        # フォールバック: requestsを使用\n",
    "        content = await extract_content_requests(url)\n",
    "    \n",
    "    return content\n",
    "\n",
    "async def extract_content_requests(url: str) -> ExtractedContent:\n",
    "    \"\"\"requestsを使用してウェブページの内容を抽出（フォールバック）\"\"\"\n",
    "    content = ExtractedContent(url=url)\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        \n",
    "        # 基本情報を抽出\n",
    "        content.title = soup.find('title').get_text().strip() if soup.find('title') else \"\"\n",
    "        \n",
    "        meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "        content.meta_description = meta_desc.get('content', '').strip() if meta_desc else \"\"\n",
    "        \n",
    "        # 見出しを抽出\n",
    "        for level in range(1, 7):\n",
    "            tag_name = f'h{level}'\n",
    "            headings = soup.find_all(tag_name)\n",
    "            if headings:\n",
    "                content.headings[tag_name] = [h.get_text().strip() for h in headings]\n",
    "        \n",
    "        # メインテキストを抽出\n",
    "        for tag in soup(['script', 'style', 'nav', 'header', 'footer']):\n",
    "            tag.decompose()\n",
    "        \n",
    "        content.main_text = soup.get_text(separator=' ', strip=True)[:8000]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 基本抽出エラー: {e}\")\n",
    "        content.title = \"抽出エラー\"\n",
    "        content.main_text = \"コンテンツの抽出に失敗しました。\"\n",
    "    \n",
    "    return content\n",
    "\n",
    "print(\"✅ ウェブページ分析機能の準備完了\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 🤖 AI分析機能を定義\nprint(\"🤖 AI分析機能を準備中...\")\n\n@dataclass\nclass AnalysisResult:\n    \"\"\"分析結果を格納するクラス\"\"\"\n    url: str\n    title: str\n    persona_analysis: str = \"\"\n    usp_analysis: str = \"\"\n    benefit_analysis: str = \"\"\n    copywriting_analysis: str = \"\"\n    summary: str = \"\"\n    processing_time: float = 0.0\n    cost_estimate: float = 0.0\n\nclass OpenAIAnalyzer:\n    \"\"\"OpenAI APIを使用したLP分析クラス\"\"\"\n    \n    def __init__(self, api_key: str):\n        self.client = AsyncOpenAI(api_key=api_key)\n        self.model = \"o4-mini\"  # OpenAI o1系リーズニングモデル\n        \n        # 分析用プロンプトテンプレート\n        self.prompts = {\n            \"persona\": {\n                \"system\": \"あなたはマーケティングの専門家です。ランディングページの内容から、ターゲット顧客のペルソナを分析してください。\",\n                \"template\": \"\"\"以下のランディングページを分析し、想定されるターゲット顧客のペルソナを詳細に分析してください。\n\n【ページ内容】\nタイトル: {title}\nメタディスクリプション: {meta_description}\n見出し: {headings}\n本文: {main_text}\n\n以下の観点でペルソナを分析してください：\n1. 年齢層・性別\n2. 職業・収入レベル\n3. ライフスタイル・価値観\n4. 抱えている課題・悩み\n5. 情報収集行動\n6. 購買決定要因\n\n分析結果は具体的で実用的な内容で回答してください。\"\"\"\n            },\n            \"usp\": {\n                \"system\": \"あなたはマーケティング戦略の専門家です。ランディングページからUSP（独自の強み）と競合優位性を抽出してください。\",\n                \"template\": \"\"\"以下のランディングページの内容からUSP（Unique Selling Proposition）と競合優位性を分析してください。\n\n【ページ内容】\nタイトル: {title}\nメタディスクリプション: {meta_description}\n見出し: {headings}\n本文: {main_text}\n\n以下の観点で分析してください：\n1. 主要なUSP・独自の強み\n2. 競合他社との差別化ポイント\n3. 顧客に提供する独自の価値\n4. 証拠・根拠となる要素\n5. 強みを支える具体的な特徴\n\n実用的で説得力のある分析結果を提供してください。\"\"\"\n            },\n            \"benefit\": {\n                \"system\": \"あなたはコピーライティングの専門家です。ランディングページからベネフィットと訴求キーワードを抽出してください。\",\n                \"template\": \"\"\"以下のランディングページの内容からベネフィットと効果的な訴求キーワードを抽出してください。\n\n【ページ内容】\nタイトル: {title}\nメタディスクリプション: {meta_description}\n見出し: {headings}\n本文: {main_text}\n\n以下の観点で分析してください：\n1. 顧客が得られる具体的なベネフィット\n2. 感情的ベネフィット vs 機能的ベネフィット\n3. 効果的な訴求キーワード\n4. パワーワード・感情を動かす表現\n5. 緊急性・希少性を示す要素\n6. 信頼性を高める要素\n\nアフィリエイト記事作成に活用できる実用的な分析結果を提供してください。\"\"\"\n            },\n            \"copywriting\": {\n                \"system\": \"あなたはコピーライティングの専門家です。ランディングページで使用されているコピーライティング手法を分析してください。\",\n                \"template\": \"\"\"以下のランディングページの内容で使用されているコピーライティング手法を分析してください。\n\n【ページ内容】\nタイトル: {title}\nメタディスクリプション: {meta_description}\n見出し: {headings}\n本文: {main_text}\n\n以下の手法が使用されているかを分析してください：\n1. AIDA（注意→関心→欲求→行動）\n2. PAS（問題→共感→解決策）\n3. BEAF（Benefit→Evidence→Advantage→Feature）\n4. 社会的証明（口コミ、推薦など）\n5. 権威性の活用\n6. 希少性・緊急性の演出\n7. ストーリーテリング\n\n具体的にどの部分でどの手法が使われているかを詳しく分析してください。\"\"\"\n            }\n        }\n    \n    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n    async def _call_api(self, system_prompt: str, user_prompt: str) -> tuple:\n        \"\"\"OpenAI APIを呼び出し（リトライ付き）\"\"\"\n        try:\n            response = await self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt},\n                    {\"role\": \"user\", \"content\": user_prompt}\n                ],\n                max_completion_tokens=4000\n            )\n            \n            content = response.choices[0].message.content\n            if not content:\n                content = \"応答が生成されませんでした。\"\n            \n            tokens = response.usage.total_tokens\n            cost = (tokens / 1000) * 0.00015  # o4-miniの概算料金\n            \n            return content, cost\n            \n        except Exception as e:\n            print(f\"⚠️ API呼び出しエラー: {e}\")\n            raise\n    \n    async def analyze_content(self, content: ExtractedContent) -> AnalysisResult:\n        \"\"\"LP内容を総合分析\"\"\"\n        start_time = time.time()\n        total_cost = 0.0\n        \n        # データ準備\n        headings_text = \"\\n\".join([f\"{level}: {', '.join(headings)}\" for level, headings in content.headings.items()])\n        \n        data = {\n            \"title\": content.title,\n            \"meta_description\": content.meta_description,\n            \"headings\": headings_text,\n            \"main_text\": content.main_text[:6000]  # トークン制限対応\n        }\n        \n        result = AnalysisResult(url=content.url, title=content.title)\n        \n        # 各分析を順次実行\n        analyses = [\n            (\"persona\", \"🎭 ペルソナ分析中...\"),\n            (\"usp\", \"💎 USP分析中...\"),\n            (\"benefit\", \"🎁 ベネフィット分析中...\"),\n            (\"copywriting\", \"✍️ コピーライティング分析中...\")\n        ]\n        \n        for analysis_type, message in analyses:\n            print(message)\n            \n            prompt_config = self.prompts[analysis_type]\n            user_prompt = prompt_config[\"template\"].format(**data)\n            \n            try:\n                analysis_result, cost = await self._call_api(\n                    prompt_config[\"system\"], \n                    user_prompt\n                )\n                total_cost += cost\n                \n                # 結果を格納\n                if analysis_type == \"persona\":\n                    result.persona_analysis = analysis_result\n                elif analysis_type == \"usp\":\n                    result.usp_analysis = analysis_result\n                elif analysis_type == \"benefit\":\n                    result.benefit_analysis = analysis_result\n                elif analysis_type == \"copywriting\":\n                    result.copywriting_analysis = analysis_result\n                    \n            except Exception as e:\n                print(f\"⚠️ {analysis_type}分析でエラー: {e}\")\n                setattr(result, f\"{analysis_type}_analysis\", f\"分析エラー: {e}\")\n        \n        # 総合サマリを生成\n        print(\"📝 総合サマリ生成中...\")\n        try:\n            summary_prompt = f\"\"\"以下のLP分析結果から、アフィリエイト記事作成に役立つ要点を3-5つのポイントでまとめてください。\n\n【ペルソナ分析】\n{result.persona_analysis[:500]}\n\n【USP分析】\n{result.usp_analysis[:500]}\n\n【ベネフィット分析】\n{result.benefit_analysis[:500]}\n\n【コピーライティング手法】\n{result.copywriting_analysis[:500]}\n\nアフィリエイト記事作成時の具体的なポイントを簡潔にまとめてください。\"\"\"\n            \n            summary, summary_cost = await self._call_api(\n                \"あなたはアフィリエイトマーケティングの専門家です。LP分析結果から記事作成のポイントをまとめてください。\",\n                summary_prompt\n            )\n            result.summary = summary\n            total_cost += summary_cost\n            \n        except Exception as e:\n            print(f\"⚠️ サマリ生成でエラー: {e}\")\n            result.summary = \"サマリの生成に失敗しました。\"\n        \n        result.processing_time = time.time() - start_time\n        result.cost_estimate = total_cost\n        \n        return result\n\nprint(\"✅ AI分析機能の準備完了\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 結果表示機能を定義\n",
    "print(\"📊 結果表示機能を準備中...\")\n",
    "\n",
    "def create_html_report(result: AnalysisResult) -> str:\n",
    "    \"\"\"分析結果をHTML形式で整形\"\"\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f8f9fa;\">\n",
    "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 15px; text-align: center; margin-bottom: 30px;\">\n",
    "            <h1 style=\"margin: 0; font-size: 2.5em; font-weight: 300;\">🎯 LP分析レポート</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; font-size: 1.2em; opacity: 0.9;\">{result.title}</p>\n",
    "            <p style=\"margin: 5px 0 0 0; font-size: 0.9em; opacity: 0.7;\">{result.url}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 30px;\">\n",
    "            <div style=\"background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);\">\n",
    "                <h3 style=\"color: #4CAF50; margin-top: 0;\">⏱️ 処理時間</h3>\n",
    "                <p style=\"font-size: 1.5em; font-weight: bold; margin: 0;\">{result.processing_time:.1f}秒</p>\n",
    "            </div>\n",
    "            <div style=\"background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);\">\n",
    "                <h3 style=\"color: #2196F3; margin-top: 0;\">💰 推定コスト</h3>\n",
    "                <p style=\"font-size: 1.5em; font-weight: bold; margin: 0;\">${result.cost_estimate:.4f}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # 各分析セクションを追加\n",
    "    sections = [\n",
    "        (\"🎭 ペルソナ分析\", result.persona_analysis, \"#FF9800\"),\n",
    "        (\"💎 USP・競合優位性\", result.usp_analysis, \"#9C27B0\"),\n",
    "        (\"🎁 ベネフィット分析\", result.benefit_analysis, \"#4CAF50\"),\n",
    "        (\"✍️ コピーライティング手法\", result.copywriting_analysis, \"#2196F3\"),\n",
    "        (\"📝 アフィリエイト記事作成ポイント\", result.summary, \"#F44336\")\n",
    "    ]\n",
    "    \n",
    "    for title, content, color in sections:\n",
    "        html += f\"\"\"\n",
    "        <div style=\"background: white; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 20px;\">\n",
    "            <h2 style=\"color: {color}; margin-top: 0; border-bottom: 2px solid {color}; padding-bottom: 10px;\">{title}</h2>\n",
    "            <div style=\"line-height: 1.6; white-space: pre-wrap;\">{content}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "        <div style=\"text-align: center; margin-top: 40px; padding: 20px; background: #e8f5e8; border-radius: 10px;\">\n",
    "            <p style=\"margin: 0; color: #2e7d32; font-weight: bold;\">🎉 分析完了！このレポートをアフィリエイト記事作成にご活用ください</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "def create_markdown_report(result: AnalysisResult) -> str:\n",
    "    \"\"\"分析結果をMarkdown形式で整形\"\"\"\n",
    "    \n",
    "    markdown = f\"\"\"# 🎯 LP分析レポート\n",
    "\n",
    "**ページタイトル**: {result.title}  \n",
    "**URL**: {result.url}  \n",
    "**分析日時**: {datetime.now().strftime('%Y年%m月%d日 %H:%M:%S')}  \n",
    "**処理時間**: {result.processing_time:.1f}秒  \n",
    "**推定コスト**: ${result.cost_estimate:.4f}\n",
    "\n",
    "---\n",
    "\n",
    "## 🎭 ペルソナ分析\n",
    "\n",
    "{result.persona_analysis}\n",
    "\n",
    "---\n",
    "\n",
    "## 💎 USP・競合優位性\n",
    "\n",
    "{result.usp_analysis}\n",
    "\n",
    "---\n",
    "\n",
    "## 🎁 ベネフィット分析\n",
    "\n",
    "{result.benefit_analysis}\n",
    "\n",
    "---\n",
    "\n",
    "## ✍️ コピーライティング手法\n",
    "\n",
    "{result.copywriting_analysis}\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 アフィリエイト記事作成ポイント\n",
    "\n",
    "{result.summary}\n",
    "\n",
    "---\n",
    "\n",
    "*このレポートは LP Analyzer により自動生成されました*\n",
    "\"\"\"\n",
    "    \n",
    "    return markdown\n",
    "\n",
    "def create_download_link(content: str, filename: str, content_type: str = \"text/plain\") -> str:\n",
    "    \"\"\"ダウンロードリンクを作成\"\"\"\n",
    "    import base64\n",
    "    \n",
    "    # コンテンツをBase64エンコード\n",
    "    b64_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')\n",
    "    \n",
    "    # ダウンロードリンクのHTML\n",
    "    download_html = f\"\"\"\n",
    "    <a href=\"data:{content_type};base64,{b64_content}\" download=\"{filename}\" \n",
    "       style=\"display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; \n",
    "              text-decoration: none; border-radius: 5px; font-weight: bold; margin: 5px;\">\n",
    "        📁 {filename} をダウンロード\n",
    "    </a>\n",
    "    \"\"\"\n",
    "    \n",
    "    return download_html\n",
    "\n",
    "print(\"✅ 結果表示機能の準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🎮 ステップ3-1: 分析するURLを設定\n\n**まず最初に、分析したいLPのURLを設定してください**  \n\n下のセルの`ANALYSIS_URLS`リストを編集して、分析したいURLを追加してください。\n\n### 📝 設定方法\n1. 下のセルを編集\n2. `ANALYSIS_URLS = [...]` の中にURLを追加\n3. 複数のURLは `,` で区切る\n4. 各URLは `\"` で囲む\n\n### 例\n```python\nANALYSIS_URLS = [\n    \"https://example.com/lp1\",\n    \"https://example.com/lp2\",\n    \"https://example.com/lp3\"\n]\n```\n\n### ⚠️ 注意\n- URLは必ず `\"` で囲んでください\n- 最後のURL以外は `,` を付けてください\n- HTTPSのURLを推奨します",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": "# 📝 URL設定エリア（ここを編集してください）\n\n# 🎯 分析したいLPのURLをここに設定してください\nANALYSIS_URLS = [\n    \"https://www.apple.com/iphone/\",\n    \"https://www.tesla.com/model3\",\n    \"https://www.airbnb.com/\"\n]\n\n# 🔍 設定確認\nprint(\"🎯 設定されたURL一覧:\")\nfor i, url in enumerate(ANALYSIS_URLS, 1):\n    print(f\"  {i}. {url}\")\n\nprint(f\"\\n📊 合計 {len(ANALYSIS_URLS)} 件のURLが設定されています\")\nprint(\"✅ 設定完了！次のセルに進んでください\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🎮 ステップ3-2: OpenAI APIキーの設定\n\n**Google Colabのシークレット機能を使用してAPIキーを設定してください（推奨）**\n\n### 🔑 設定方法\n1. 左サイドバーの**🔑アイコン**をクリック\n2. **「新しいシークレットを追加」**をクリック\n3. 名前: `OPENAI_API_KEY`\n4. 値: あなたのOpenAI APIキー（sk-で始まる文字列）\n5. **「ノートブックアクセス」**を有効にする\n\n### 🔄 代替方法\nシークレット機能が使えない場合は、下のセルで直接APIキーを設定できます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 🔑 APIキー設定確認\n\n# Google ColabのシークレットからAPIキーを取得\napi_key_available = False\nOPENAI_API_KEY = None\n\ntry:\n    from google.colab import userdata\n    try:\n        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n        print(\"✅ Google ColabのシークレットからAPIキーを取得しました\")\n        api_key_available = True\n    except Exception:\n        print(\"❌ Google ColabのシークレットでOPENAI_API_KEYが設定されていません\")\n        print(\"\\n📋 設定方法:\")\n        print(\"   1. 左サイドバーの🔑アイコンをクリック\")\n        print(\"   2. 「新しいシークレットを追加」をクリック\")  \n        print(\"   3. 名前: OPENAI_API_KEY\")\n        print(\"   4. 値: あなたのOpenAI APIキー (sk-で始まる文字列)\")\n        print(\"   5. ノートブックアクセスを有効にする\")\n        print(\"\\n💡 設定後、このセルを再実行してください\")\n        \nexcept ImportError:\n    print(\"⚠️ Google Colab環境が検出されませんでした\")\n    print(\"💡 このNotebookはGoogle Colab専用です\")\n\n# 設定状況の確認\nif api_key_available:\n    print(f\"🎯 APIキー: {OPENAI_API_KEY[:10]}...（設定済み）\")\n    print(\"✅ 準備完了！次のセルに進んでください\")\nelse:\n    print(\"❌ APIキーが設定されていません\")\n    print(\"💡 上記の手順に従ってAPIキーを設定してから再実行してください\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🚀 ステップ3-3: LP分析の実行\n\n**準備が完了したら、下のセルを実行して分析を開始してください**\n\n### 📊 分析内容\n- 🎭 **ペルソナ分析**: ターゲット顧客の特定\n- 💎 **USP抽出**: 独自の強みと競合優位性\n- 🎁 **ベネフィット分析**: 顧客が得られる価値\n- ✍️ **コピーライティング手法**: 使用されている心理テクニック\n- 📝 **記事作成ガイド**: アフィリエイト記事のポイント\n\n### ⏱️ 所要時間\n- 1つのLP: 約30秒〜1分\n- 複数のLP: LP数 × 約1分\n\n### 💰 コスト目安\n- 1つのLP: 約$0.01〜0.05（1円〜5円程度）",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 🚀 LP分析実行\n\nimport asyncio\nimport time\nfrom datetime import datetime\nfrom IPython.display import display, HTML\n\n# 必要なライブラリの確認\ntry:\n    import nest_asyncio\nexcept ImportError:\n    print(\"📦 nest_asyncioをインストール中...\")\n    import subprocess\n    import sys\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\", \"-q\"])\n    import nest_asyncio\n\n# 事前チェック\nprint(\"🔍 事前チェックを実行中...\")\n\n# APIキーの確認\nif not api_key_available or not OPENAI_API_KEY:\n    print(\"❌ APIキーが設定されていません\")\n    print(\"💡 前のセルでAPIキーを設定してから再実行してください\")\n    exit()\n\n# URLの確認\nif not ANALYSIS_URLS:\n    print(\"❌ 分析するURLが設定されていません\")\n    print(\"💡 URL設定セルでURLを設定してから再実行してください\")\n    exit()\n\nprint(f\"✅ APIキー: 設定済み\")\nprint(f\"✅ 分析URL: {len(ANALYSIS_URLS)}件\")\n\n# 分析開始\nprint(f\"\\n{'='*60}\")\nprint(f\"🎯 LP分析を開始します\")\nprint(f\"{'='*60}\")\nprint(f\"📊 分析対象: {len(ANALYSIS_URLS)}件のLP\")\nprint(f\"🕐 開始時刻: {datetime.now().strftime('%Y年%m月%d日 %H:%M:%S')}\")\n\n# 分析器を初期化\ntry:\n    analyzer = OpenAIAnalyzer(OPENAI_API_KEY)\n    print(\"✅ AI分析エンジンの初期化完了\")\nexcept Exception as e:\n    print(f\"❌ AI分析エンジンの初期化エラー: {e}\")\n    exit()\n\n# 結果保存用\nanalysis_results = []\ntotal_cost = 0.0\n\n# nest_asyncioを適用（Google Colab対応）\nnest_asyncio.apply()\n\n# 各URLを順次分析\nfor i, url in enumerate(ANALYSIS_URLS, 1):\n    print(f\"\\n{'='*50}\")\n    print(f\"📊 {i}/{len(ANALYSIS_URLS)}: {url}\")\n    print(f\"{'='*50}\")\n    \n    try:\n        # ステップ1: コンテンツ抽出\n        print(\"🔍 ウェブページの内容を抽出中...\")\n        \n        # 非同期関数を同期的に実行\n        loop = asyncio.get_event_loop()\n        \n        if playwright_available:\n            content = loop.run_until_complete(extract_content_playwright(url))\n        else:\n            content = loop.run_until_complete(extract_content_requests(url))\n        \n        if not content.title or content.title == \"抽出エラー\":\n            print(f\"⚠️ {url} のコンテンツ抽出に失敗しました\")\n            continue\n        \n        print(f\"✅ 抽出完了: {content.title}\")\n        \n        # ステップ2: AI分析\n        print(\"\\n🤖 AIによる詳細分析を開始...\")\n        result = loop.run_until_complete(analyzer.analyze_content(content))\n        \n        analysis_results.append(result)\n        total_cost += result.cost_estimate\n        \n        print(f\"✅ 分析完了! 処理時間: {result.processing_time:.1f}秒, コスト: ${result.cost_estimate:.4f}\")\n        \n        # ステップ3: 結果表示\n        print(\"\\n📊 結果を表示中...\")\n        html_report = create_html_report(result)\n        display(HTML(html_report))\n        \n        # ダウンロードリンク作成\n        markdown_report = create_markdown_report(result)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"LP分析レポート_{timestamp}_{i}.md\"\n        \n        download_link = create_download_link(\n            markdown_report, \n            filename, \n            \"text/markdown\"\n        )\n        display(HTML(download_link))\n        \n    except Exception as e:\n        print(f\"❌ {url} の分析でエラーが発生: {e}\")\n        import traceback\n        print(f\"詳細エラー: {traceback.format_exc()}\")\n        continue\n\n# 総合結果\nprint(f\"\\n\\n{'='*60}\")\nprint(f\"🎉 全ての分析が完了しました！\")\nprint(f\"{'='*60}\")\nprint(f\"📊 分析成功: {len(analysis_results)}/{len(ANALYSIS_URLS)}件\")\nprint(f\"💰 総コスト: ${total_cost:.4f}\")\nprint(f\"⏱️ 総処理時間: {sum(r.processing_time for r in analysis_results):.1f}秒\")\nprint(f\"🕐 完了時刻: {datetime.now().strftime('%Y年%m月%d日 %H:%M:%S')}\")\n\nif len(analysis_results) > 1:\n    # 統合レポート作成\n    print(\"\\n📋 統合レポートを作成中...\")\n    \n    integrated_markdown = f\"\"\"# 🎯 LP分析統合レポート\n\n**分析日時**: {datetime.now().strftime('%Y年%m月%d日 %H:%M:%S')}  \n**分析件数**: {len(analysis_results)}件  \n**総コスト**: ${total_cost:.4f}  \n**総処理時間**: {sum(r.processing_time for r in analysis_results):.1f}秒\n\n---\n\n\"\"\"\n    \n    for i, result in enumerate(analysis_results, 1):\n        integrated_markdown += f\"\"\"## {i}. {result.title}\n\n**URL**: {result.url}\n\n### 📝 記事作成ポイント\n{result.summary}\n\n---\n\n\"\"\"\n    \n    # 統合レポートのダウンロードリンク\n    integrated_filename = f\"LP分析統合レポート_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n    integrated_download = create_download_link(\n        integrated_markdown,\n        integrated_filename,\n        \"text/markdown\"\n    )\n    \n    display(HTML(f\"<div style='margin-top: 30px;'><h2>📋 統合レポート</h2>{integrated_download}</div>\"))\n\nprint(\"\\n🎉 お疲れ様でした！分析結果をアフィリエイト記事作成にご活用ください\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}